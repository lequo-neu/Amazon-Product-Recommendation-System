{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection & Preprocessing\n",
        "\n",
        "## Overview\n",
        "This notebook downloads and preprocesses Amazon 2023 product review data from McAuley Lab. It handles downloading raw CSV files, converting to Parquet format, creating stratified samples, and processing metadata. The pipeline ensures data consistency across train/validation/test splits while maintaining the 5-core property (each user and item has at least 5 interactions).\n",
        "\n",
        "## Notebook Structure\n",
        "1. **Setup**: Import libraries, configure paths, and define constants\n",
        "2. **Download Functions**: Fetch raw data from URLs with retry logic\n",
        "3. **Conversion**: Transform CSV.GZ to Parquet for efficient storage\n",
        "4. **Sampling**: Create stratified samples (small/medium/large/big) maintaining user-item distributions\n",
        "5. **Metadata Processing**: Download and extract essential product information (title, features, description, etc.)\n",
        "6. **Pipeline**: Automated execution for all categories\n",
        "\n",
        "## Process Flow\n",
        "**Data Collection:**\n",
        "- For each category: Download train/valid/test CSV.GZ from McAuley Lab → Convert to Parquet\n",
        "- Download metadata JSONL.GZ → Extract essential fields → Save as Parquet\n",
        "\n",
        "**Sampling:**\n",
        "- Create samples from full dataset: small (2k users), medium (20k), large (50k), big (50k with item filtering)\n",
        "- For train: Sample top N active users → Filter items by popularity threshold\n",
        "- For valid/test: Filter to match train users and items for consistency\n",
        "\n",
        "**Output:**\n",
        "- Full datasets: `category.5core.{split}.parquet`\n",
        "- Samples: `category.5core.{split}.{size}.parquet`\n",
        "- Metadata: `category.meta.parquet`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os, json, gzip, urllib.request\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "\n",
        "module_path = str((Path(\"..\") / \"utilities\").resolve())\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from logger import Logger\n",
        "from configurations import Configurations\n",
        "\n",
        "logger = Logger(process_name=\"data_collection\", log_file=Configurations.LOG_PATH)\n",
        "\n",
        "RAW_DIR = Path(Configurations.DATA_RAW_PATH)\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PROCESSED_DIR = Path(Configurations.DATA_PROCESSED_PATH)\n",
        "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CATEGORIES = Configurations.CATEGORIES\n",
        "CORES = Configurations.CORES\n",
        "SPLITS = Configurations.SPLITS\n",
        "BASE_URL = Configurations.BASE_URL\n",
        "meta_base_url = \"https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_{category}.jsonl.gz\"\n",
        "meta_urls = {cat: meta_base_url.format(category=cat) for cat in CATEGORIES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_url(core: str, category: str, split: str) -> str:\n",
        "    return f\"{BASE_URL}/{core}/last_out_w_his/{category}.{split}.csv.gz\"\n",
        "\n",
        "def local_path_for_parquet(core: str, category: str, split: str, sample: str = None, raw_dir=RAW_DIR) -> Path:\n",
        "    safe_cat = category.replace(\"/\", \"-\")\n",
        "    if raw_dir == RAW_DIR:\n",
        "        return RAW_DIR / f\"{safe_cat}.{core}.{split}.csv.gz\"\n",
        "    elif raw_dir == PROCESSED_DIR:\n",
        "        if sample is None:\n",
        "            return PROCESSED_DIR / f\"{safe_cat}.{core}.{split}.parquet\"\n",
        "        else:\n",
        "            return PROCESSED_DIR / f\"{safe_cat}.{core}.{split}.{sample}.parquet\"\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid directory: {raw_dir}\")\n",
        "\n",
        "def download_file(url: str, out_path: Path, max_retries: int = 3) -> None:\n",
        "    if out_path.exists() and out_path.stat().st_size > 0:\n",
        "        logger.log_info(f\"Exists, skip: {out_path.name}\")\n",
        "        return\n",
        "    attempt = 0\n",
        "    while attempt < max_retries:\n",
        "        try:\n",
        "            attempt += 1\n",
        "            logger.log_info(f\"Downloading (attempt {attempt}/{max_retries}): {url}\")\n",
        "            tmp = str(out_path) + \".part\"\n",
        "            urllib.request.urlretrieve(url, tmp)\n",
        "            os.replace(tmp, out_path)\n",
        "            logger.log_info(f\"Saved: {out_path.name}\")\n",
        "            return\n",
        "        except Exception as e:\n",
        "            logger.log_warning(f\"Failed attempt {attempt} for {url}: {e}\")\n",
        "    raise RuntimeError(f\"Exceeded retries: {url}\")\n",
        "\n",
        "def save_dataset_to_parquet(csv_gz_path: Path, out_parquet_path: Path):\n",
        "    if out_parquet_path.exists():\n",
        "        logger.log_info(f\"Skip: {out_parquet_path.name}\")\n",
        "        return\n",
        "    logger.log_info(f\"Reading: {csv_gz_path.name}\")\n",
        "    df = pl.from_pandas(pd.read_csv(csv_gz_path, compression='gzip')[Configurations.COLUMNS])\n",
        "    logger.log_info(f\"  Shape: {df.shape}\")\n",
        "    logger.log_info(f\"  Users: {df['user_id'].n_unique():,}\")\n",
        "    logger.log_info(f\"  Items: {df['parent_asin'].n_unique():,}\")\n",
        "    df.to_pandas().to_parquet(out_parquet_path, engine='pyarrow', index=False)\n",
        "    logger.log_info(f\"Saved: {out_parquet_path.name}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_n_sample(input_path: Path, n: int, item_mult: float = 1.0, n_name_out: str = None):\n",
        "    stem = input_path.stem\n",
        "    parts = stem.split('.')\n",
        "    category, core, split = parts[0], parts[1] if len(parts) > 1 else '5core', parts[2] if len(parts) > 2 else 'train'\n",
        "    output_path = input_path.parent / f\"{category}.{core}.{split}.{n_name_out}.parquet\"\n",
        "    \n",
        "    if output_path.exists():\n",
        "        logger.log_info(f\"Skip: {output_path.name}\")\n",
        "        return\n",
        "    \n",
        "    logger.log_info(f\"\\nSampling {n} users\")\n",
        "    logger.log_info(f\"  Input:  {input_path.name}\")\n",
        "    logger.log_info(f\"  Output: {output_path.name}\")\n",
        "    \n",
        "    df = pl.read_parquet(input_path)\n",
        "    total = df['user_id'].n_unique()\n",
        "    logger.log_info(f\"  Total users: {total:,}\")\n",
        "    \n",
        "    if split == 'train':\n",
        "        if n >= total:\n",
        "            df_sampled = df\n",
        "            users_n = df['user_id'].unique().to_list()\n",
        "        else:\n",
        "            activity = df.group_by('user_id').agg(pl.len().alias('n')).sort('n', descending=True)\n",
        "            users_n = activity.head(n)['user_id'].to_list()\n",
        "            df_sampled = df.filter(pl.col('user_id').is_in(users_n))\n",
        "        \n",
        "        if item_mult > 1.0:\n",
        "            logger.log_info(f\"  Before item filter: {df_sampled.shape} shape, {len(df_sampled):,} ratings, {df_sampled['user_id'].n_unique():,}  users, {df_sampled['parent_asin'].n_unique():,} items\")\n",
        "            item_counts = df_sampled.group_by('parent_asin').agg(pl.len().alias('n'))\n",
        "            avg_item = item_counts['n'].mean()\n",
        "            min_item = avg_item * item_mult\n",
        "            logger.log_info(f\"  Avg ratings/item: {avg_item:.2f}\")\n",
        "            logger.log_info(f\"  Min threshold: {min_item:.2f} ({item_mult}x avg)\")\n",
        "            popular = item_counts.filter(pl.col('n') > min_item)['parent_asin'].to_list()\n",
        "            df_sampled = df_sampled.filter(pl.col('parent_asin').is_in(popular))\n",
        "            logger.log_info(f\"  After item filter: {df_sampled.shape} shape, {len(df_sampled):,} ratings, {df_sampled['user_id'].n_unique():,}  users, {df_sampled['parent_asin'].n_unique():,} items\")\n",
        "        \n",
        "        logger.log_info(f\"  Sampled: {df_sampled.shape} shape, {len(df_sampled):,} ratings, {len(users_n):,} users\")\n",
        "    else:\n",
        "        train_path = input_path.parent / f\"{category}.{core}.train.{n_name_out}.parquet\"\n",
        "        if not train_path.exists():\n",
        "            logger.log_warning(f\"  Train sample not found: {train_path.name}\")\n",
        "            return\n",
        "        df_train = pl.read_parquet(train_path)\n",
        "        users_n = df_train['user_id'].unique().to_list()\n",
        "        items_n = df_train['parent_asin'].unique().to_list()\n",
        "        df_sampled = df.filter(pl.col('user_id').is_in(users_n) & pl.col('parent_asin').is_in(items_n))\n",
        "        logger.log_info(f\"  Filtered: {len(df_sampled):,} ratings, {df_sampled['user_id'].n_unique():,} users\")\n",
        "    \n",
        "    df_sampled.to_pandas().to_parquet(output_path, engine='pyarrow', index=False)\n",
        "    logger.log_info(f\"  Saved: {output_path.name}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_meta(category: str, url: str = None):\n",
        "    url = url or meta_urls.get(category)\n",
        "    if not url:\n",
        "        return\n",
        "    dst = RAW_DIR / f\"{category}.meta.jsonl.gz\"\n",
        "    if dst.exists() and dst.stat().st_size > 0:\n",
        "        logger.log_info(f\"[META] Skip: {dst.name}\")\n",
        "        return\n",
        "    logger.log_info(f\"[META] Downloading: {category}\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, str(dst))\n",
        "        logger.log_info(f\"[META] {dst.name}\")\n",
        "    except Exception as e:\n",
        "        logger.log_exception(f\"[META] Failed: {e}\")\n",
        "\n",
        "def save_meta_for_training_ui(category: str):\n",
        "    safe_cat = category.replace('/', '-')\n",
        "    out_path = PROCESSED_DIR / f\"{safe_cat}.meta.parquet\"\n",
        "    \n",
        "    if out_path.exists():\n",
        "        logger.log_info(f\"[META] Skip: {out_path.name}\")\n",
        "        return out_path\n",
        "    \n",
        "    fp = RAW_DIR / f\"{category}.meta.jsonl.gz\"\n",
        "    if not fp.exists():\n",
        "        logger.log_warning(f\"[META] Not found: {fp}\")\n",
        "        return None\n",
        "    \n",
        "    logger.log_info(f\"[META] Reading: {fp.name}\")\n",
        "    \n",
        "    def extract_item(obj):\n",
        "        def process_list(field, max_items):\n",
        "            if not isinstance(field, list):\n",
        "                return []\n",
        "            if field and isinstance(field[0], list):\n",
        "                field = field[0]\n",
        "            return field[:max_items]\n",
        "        \n",
        "        def process_desc(desc, max_len=2000):\n",
        "            if isinstance(desc, list):\n",
        "                desc = \" \".join(str(d) for d in desc if d)\n",
        "            elif not desc:\n",
        "                return \"\"\n",
        "            else:\n",
        "                desc = str(desc)\n",
        "            return desc[:max_len] + (\"...\" if len(desc) > max_len else \"\")\n",
        "        \n",
        "        def process_images(img_list):\n",
        "            if not img_list or not isinstance(img_list, list):\n",
        "                return []\n",
        "            return [{\"hi_res\": img.get(\"hi_res\"), \"thumb\": img.get(\"thumb\")} \n",
        "                    for img in img_list[:3] if isinstance(img, dict)]\n",
        "        \n",
        "        return {\n",
        "            \"parent_asin\": obj.get(\"parent_asin\"),\n",
        "            \"title\": obj.get(\"title\", \"\"),\n",
        "            \"price\": obj.get(\"price\"),\n",
        "            \"average_rating\": obj.get(\"average_rating\"),\n",
        "            \"rating_number\": obj.get(\"rating_number\"),\n",
        "            \"features\": process_list(obj.get(\"features\"), 10),\n",
        "            \"description\": process_desc(obj.get(\"description\")),\n",
        "            \"categories\": process_list(obj.get(\"categories\"), 5),\n",
        "            \"images\": process_images(obj.get(\"images\")),\n",
        "            \"store\": obj.get(\"store\", \"\")\n",
        "        }\n",
        "    \n",
        "    rows = []\n",
        "    with gzip.open(fp, \"rt\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "                if obj.get(\"parent_asin\"):\n",
        "                    rows.append(extract_item(obj))\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    if not rows:\n",
        "        logger.log_warning(f\"[META] No data for {category}\")\n",
        "        return None\n",
        "    \n",
        "    df = pd.DataFrame(rows)\n",
        "    for col in ['price', 'average_rating', 'rating_number']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    for col in ['title', 'description', 'store']:\n",
        "        df[col] = df[col].fillna('')\n",
        "    \n",
        "    df.to_parquet(out_path, index=False)\n",
        "    logger.log_info(f\"[META] {out_path.name}: {len(df):,} items\")\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run():\n",
        "    logger.log_info(\"=\"*70)\n",
        "    logger.log_info(\"DATASET COLLECTION\")\n",
        "    logger.log_info(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    for core in CORES:\n",
        "        for cat in CATEGORIES:\n",
        "            logger.log_info(f\"\\n{'='*70}\")\n",
        "            logger.log_info(f\"{cat}\")\n",
        "            logger.log_info(f\"{'='*70}\")\n",
        "            \n",
        "            for split in SPLITS:\n",
        "                logger.log_info(f\"\\nProcessing {split.upper()}...\")\n",
        "                url = build_url(core, cat, split)\n",
        "                in_path = local_path_for_parquet(core, cat, split, raw_dir=RAW_DIR)\n",
        "                out_path = local_path_for_parquet(core, cat, split, raw_dir=PROCESSED_DIR)\n",
        "                try:\n",
        "                    download_file(url, in_path)\n",
        "                    save_dataset_to_parquet(in_path, out_path)\n",
        "                except Exception as e:\n",
        "                    logger.log_exception(f\"{split} error: {e}\")\n",
        "\n",
        "    logger.log_info(\"\\n\" + \"=\"*70)\n",
        "    logger.log_info(\"METADATA\")\n",
        "    logger.log_info(\"=\"*70)\n",
        "    \n",
        "    for cat in CATEGORIES:\n",
        "        download_meta(cat)\n",
        "        save_meta_for_training_ui(cat)\n",
        "\n",
        "    logger.log_info(\"\\n\" + \"=\"*70)\n",
        "    logger.log_info(\"CREATING SAMPLES\")\n",
        "    logger.log_info(\"=\"*70)\n",
        "    \n",
        "    for core in CORES:\n",
        "        for cat in CATEGORIES:\n",
        "            for split in SPLITS:\n",
        "                for sample in Configurations.SAMPLE_SIZES:\n",
        "                    if sample != \"full\":\n",
        "                        n = Configurations.SAMPLE_SIZES[sample]\n",
        "                        logger.log_info(f\"\\ncat={cat} - split={split} - sample={sample} - n={n} sampling...\")\n",
        "                        in_path = local_path_for_parquet(core, cat, split, raw_dir=PROCESSED_DIR)\n",
        "                        out_path = local_path_for_parquet(core, cat, split, sample, raw_dir=PROCESSED_DIR)\n",
        "                        logger.log_info(f\"Input: {in_path.name} \\n → Output: {out_path.name}\")\n",
        "                        create_n_sample(in_path, n, Configurations.ITEM_MULTI, sample)\n",
        "\n",
        "    logger.log_info(\"\\n COMPLETED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-24 21:13:38,410 - INFO - ======================================================================\n",
            "2025-10-24 21:13:38,411 - INFO - DATASET COLLECTION\n",
            "2025-10-24 21:13:38,411 - INFO - ======================================================================\n",
            "\n",
            "2025-10-24 21:13:38,411 - INFO - \n",
            "======================================================================\n",
            "2025-10-24 21:13:38,411 - INFO - Electronics\n",
            "2025-10-24 21:13:38,412 - INFO - ======================================================================\n",
            "2025-10-24 21:13:38,412 - INFO - \n",
            "Processing TRAIN...\n",
            "2025-10-24 21:13:38,412 - INFO - Exists, skip: Electronics.5core.train.csv.gz\n",
            "2025-10-24 21:13:38,413 - INFO - Skip: Electronics.5core.train.parquet\n",
            "2025-10-24 21:13:38,413 - INFO - \n",
            "Processing VALID...\n",
            "2025-10-24 21:13:38,428 - INFO - Exists, skip: Electronics.5core.valid.csv.gz\n",
            "2025-10-24 21:13:38,428 - INFO - Skip: Electronics.5core.valid.parquet\n",
            "2025-10-24 21:13:38,429 - INFO - \n",
            "Processing TEST...\n",
            "2025-10-24 21:13:38,429 - INFO - Exists, skip: Electronics.5core.test.csv.gz\n",
            "2025-10-24 21:13:38,450 - INFO - Skip: Electronics.5core.test.parquet\n",
            "2025-10-24 21:13:38,451 - INFO - \n",
            "======================================================================\n",
            "2025-10-24 21:13:38,451 - INFO - Beauty_and_Personal_Care\n",
            "2025-10-24 21:13:38,452 - INFO - ======================================================================\n",
            "2025-10-24 21:13:38,452 - INFO - \n",
            "Processing TRAIN...\n",
            "2025-10-24 21:13:38,452 - INFO - Exists, skip: Beauty_and_Personal_Care.5core.train.csv.gz\n",
            "2025-10-24 21:13:38,453 - INFO - Skip: Beauty_and_Personal_Care.5core.train.parquet\n",
            "2025-10-24 21:13:38,453 - INFO - \n",
            "Processing VALID...\n",
            "2025-10-24 21:13:38,454 - INFO - Exists, skip: Beauty_and_Personal_Care.5core.valid.csv.gz\n",
            "2025-10-24 21:13:38,454 - INFO - Skip: Beauty_and_Personal_Care.5core.valid.parquet\n",
            "2025-10-24 21:13:38,455 - INFO - \n",
            "Processing TEST...\n",
            "2025-10-24 21:13:38,458 - INFO - Exists, skip: Beauty_and_Personal_Care.5core.test.csv.gz\n",
            "2025-10-24 21:13:38,462 - INFO - Skip: Beauty_and_Personal_Care.5core.test.parquet\n",
            "2025-10-24 21:13:38,464 - INFO - \n",
            "======================================================================\n",
            "2025-10-24 21:13:38,464 - INFO - Sports_and_Outdoors\n",
            "2025-10-24 21:13:38,465 - INFO - ======================================================================\n",
            "2025-10-24 21:13:38,465 - INFO - \n",
            "Processing TRAIN...\n",
            "2025-10-24 21:13:38,465 - INFO - Exists, skip: Sports_and_Outdoors.5core.train.csv.gz\n",
            "2025-10-24 21:13:38,465 - INFO - Skip: Sports_and_Outdoors.5core.train.parquet\n",
            "2025-10-24 21:13:38,466 - INFO - \n",
            "Processing VALID...\n",
            "2025-10-24 21:13:38,466 - INFO - Exists, skip: Sports_and_Outdoors.5core.valid.csv.gz\n",
            "2025-10-24 21:13:38,466 - INFO - Skip: Sports_and_Outdoors.5core.valid.parquet\n",
            "2025-10-24 21:13:38,466 - INFO - \n",
            "Processing TEST...\n",
            "2025-10-24 21:13:38,467 - INFO - Exists, skip: Sports_and_Outdoors.5core.test.csv.gz\n",
            "2025-10-24 21:13:38,467 - INFO - Skip: Sports_and_Outdoors.5core.test.parquet\n",
            "2025-10-24 21:13:38,467 - INFO - \n",
            "======================================================================\n",
            "2025-10-24 21:13:38,467 - INFO - METADATA\n",
            "2025-10-24 21:13:38,468 - INFO - ======================================================================\n",
            "2025-10-24 21:13:38,468 - INFO - [META] Skip: Electronics.meta.jsonl.gz\n",
            "2025-10-24 21:13:38,468 - INFO - [META] Skip: Electronics.meta.parquet\n",
            "2025-10-24 21:13:38,469 - INFO - [META] Skip: Beauty_and_Personal_Care.meta.jsonl.gz\n",
            "2025-10-24 21:13:38,469 - INFO - [META] Skip: Beauty_and_Personal_Care.meta.parquet\n",
            "2025-10-24 21:13:38,469 - INFO - [META] Skip: Sports_and_Outdoors.meta.jsonl.gz\n",
            "2025-10-24 21:13:38,469 - INFO - [META] Skip: Sports_and_Outdoors.meta.parquet\n",
            "2025-10-24 21:13:38,470 - INFO - \n",
            "======================================================================\n",
            "2025-10-24 21:13:38,470 - INFO - CREATING SAMPLES\n",
            "2025-10-24 21:13:38,470 - INFO - ======================================================================\n",
            "2025-10-24 21:13:38,471 - INFO - \n",
            "cat=Electronics - split=train - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:38,471 - INFO - Input: Electronics.5core.train.parquet \n",
            " → Output: Electronics.5core.train.large.parquet\n",
            "2025-10-24 21:13:38,471 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:38,471 - INFO -   Input:  Electronics.5core.train.parquet\n",
            "2025-10-24 21:13:38,472 - INFO -   Output: Electronics.5core.train.large.parquet\n",
            "2025-10-24 21:13:39,011 - INFO -   Total users: 1,641,026\n",
            "2025-10-24 21:13:39,615 - INFO -   Before item filter: (2109031, 4) shape, 2,109,031 ratings, 50,000  users, 279,513 items\n",
            "2025-10-24 21:13:39,689 - INFO -   Avg ratings/item: 7.55\n",
            "2025-10-24 21:13:39,689 - INFO -   Min threshold: 679.08 (90x avg)\n",
            "2025-10-24 21:13:39,700 - INFO -   After item filter: (86614, 4) shape, 86,614 ratings, 35,582  users, 83 items\n",
            "2025-10-24 21:13:39,701 - INFO -   Sampled: (86614, 4) shape, 86,614 ratings, 50,000 users\n",
            "2025-10-24 21:13:39,908 - INFO -   Saved: Electronics.5core.train.large.parquet\n",
            "\n",
            "2025-10-24 21:13:39,918 - INFO - \n",
            "cat=Electronics - split=train - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:39,918 - INFO - Input: Electronics.5core.train.parquet \n",
            " → Output: Electronics.5core.train.big.parquet\n",
            "2025-10-24 21:13:39,919 - INFO - Skip: Electronics.5core.train.big.parquet\n",
            "2025-10-24 21:13:39,919 - INFO - \n",
            "cat=Electronics - split=valid - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:39,919 - INFO - Input: Electronics.5core.valid.parquet \n",
            " → Output: Electronics.5core.valid.large.parquet\n",
            "2025-10-24 21:13:39,920 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:39,920 - INFO -   Input:  Electronics.5core.valid.parquet\n",
            "2025-10-24 21:13:39,920 - INFO -   Output: Electronics.5core.valid.large.parquet\n",
            "2025-10-24 21:13:40,079 - INFO -   Total users: 1,641,026\n",
            "2025-10-24 21:13:40,108 - INFO -   Filtered: 875 ratings, 875 users\n",
            "2025-10-24 21:13:40,111 - INFO -   Saved: Electronics.5core.valid.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,113 - INFO - \n",
            "cat=Electronics - split=valid - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,113 - INFO - Input: Electronics.5core.valid.parquet \n",
            " → Output: Electronics.5core.valid.big.parquet\n",
            "2025-10-24 21:13:40,113 - INFO - Skip: Electronics.5core.valid.big.parquet\n",
            "2025-10-24 21:13:40,114 - INFO - \n",
            "cat=Electronics - split=test - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,114 - INFO - Input: Electronics.5core.test.parquet \n",
            " → Output: Electronics.5core.test.large.parquet\n",
            "2025-10-24 21:13:40,115 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:40,115 - INFO -   Input:  Electronics.5core.test.parquet\n",
            "2025-10-24 21:13:40,115 - INFO -   Output: Electronics.5core.test.large.parquet\n",
            "2025-10-24 21:13:40,277 - INFO -   Total users: 1,641,026\n",
            "2025-10-24 21:13:40,305 - INFO -   Filtered: 684 ratings, 684 users\n",
            "2025-10-24 21:13:40,308 - INFO -   Saved: Electronics.5core.test.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,309 - INFO - \n",
            "cat=Electronics - split=test - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,310 - INFO - Input: Electronics.5core.test.parquet \n",
            " → Output: Electronics.5core.test.big.parquet\n",
            "2025-10-24 21:13:40,310 - INFO - Skip: Electronics.5core.test.big.parquet\n",
            "2025-10-24 21:13:40,310 - INFO - \n",
            "cat=Beauty_and_Personal_Care - split=train - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,310 - INFO - Input: Beauty_and_Personal_Care.5core.train.parquet \n",
            " → Output: Beauty_and_Personal_Care.5core.train.large.parquet\n",
            "2025-10-24 21:13:40,311 - INFO - Skip: Beauty_and_Personal_Care.5core.train.large.parquet\n",
            "2025-10-24 21:13:40,311 - INFO - \n",
            "cat=Beauty_and_Personal_Care - split=train - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,311 - INFO - Input: Beauty_and_Personal_Care.5core.train.parquet \n",
            " → Output: Beauty_and_Personal_Care.5core.train.big.parquet\n",
            "2025-10-24 21:13:40,311 - INFO - Skip: Beauty_and_Personal_Care.5core.train.big.parquet\n",
            "2025-10-24 21:13:40,312 - INFO - \n",
            "cat=Beauty_and_Personal_Care - split=valid - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,312 - INFO - Input: Beauty_and_Personal_Care.5core.valid.parquet \n",
            " → Output: Beauty_and_Personal_Care.5core.valid.large.parquet\n",
            "2025-10-24 21:13:40,312 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:40,313 - INFO -   Input:  Beauty_and_Personal_Care.5core.valid.parquet\n",
            "2025-10-24 21:13:40,313 - INFO -   Output: Beauty_and_Personal_Care.5core.valid.large.parquet\n",
            "2025-10-24 21:13:40,392 - INFO -   Total users: 729,576\n",
            "2025-10-24 21:13:40,404 - INFO -   Filtered: 66 ratings, 66 users\n",
            "2025-10-24 21:13:40,406 - INFO -   Saved: Beauty_and_Personal_Care.5core.valid.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,407 - INFO - \n",
            "cat=Beauty_and_Personal_Care - split=valid - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,407 - INFO - Input: Beauty_and_Personal_Care.5core.valid.parquet \n",
            " → Output: Beauty_and_Personal_Care.5core.valid.big.parquet\n",
            "2025-10-24 21:13:40,407 - INFO - Skip: Beauty_and_Personal_Care.5core.valid.big.parquet\n",
            "2025-10-24 21:13:40,408 - INFO - \n",
            "cat=Beauty_and_Personal_Care - split=test - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,408 - INFO - Input: Beauty_and_Personal_Care.5core.test.parquet \n",
            " → Output: Beauty_and_Personal_Care.5core.test.large.parquet\n",
            "2025-10-24 21:13:40,408 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:40,409 - INFO -   Input:  Beauty_and_Personal_Care.5core.test.parquet\n",
            "2025-10-24 21:13:40,409 - INFO -   Output: Beauty_and_Personal_Care.5core.test.large.parquet\n",
            "2025-10-24 21:13:40,490 - INFO -   Total users: 729,576\n",
            "2025-10-24 21:13:40,499 - INFO -   Filtered: 65 ratings, 65 users\n",
            "2025-10-24 21:13:40,501 - INFO -   Saved: Beauty_and_Personal_Care.5core.test.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,502 - INFO - \n",
            "cat=Beauty_and_Personal_Care - split=test - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,502 - INFO - Input: Beauty_and_Personal_Care.5core.test.parquet \n",
            " → Output: Beauty_and_Personal_Care.5core.test.big.parquet\n",
            "2025-10-24 21:13:40,503 - INFO - Skip: Beauty_and_Personal_Care.5core.test.big.parquet\n",
            "2025-10-24 21:13:40,503 - INFO - \n",
            "cat=Sports_and_Outdoors - split=train - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,503 - INFO - Input: Sports_and_Outdoors.5core.train.parquet \n",
            " → Output: Sports_and_Outdoors.5core.train.large.parquet\n",
            "2025-10-24 21:13:40,504 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:40,504 - INFO -   Input:  Sports_and_Outdoors.5core.train.parquet\n",
            "2025-10-24 21:13:40,504 - INFO -   Output: Sports_and_Outdoors.5core.train.large.parquet\n",
            "2025-10-24 21:13:40,616 - INFO -   Total users: 409,772\n",
            "2025-10-24 21:13:40,761 - INFO -   Before item filter: (959332, 4) shape, 959,332 ratings, 50,000  users, 139,211 items\n",
            "2025-10-24 21:13:40,789 - INFO -   Avg ratings/item: 6.89\n",
            "2025-10-24 21:13:40,790 - INFO -   Min threshold: 620.21 (90x avg)\n",
            "2025-10-24 21:13:40,792 - INFO -   After item filter: (3240, 4) shape, 3,240 ratings, 3,070  users, 3 items\n",
            "2025-10-24 21:13:40,793 - INFO -   Sampled: (3240, 4) shape, 3,240 ratings, 50,000 users\n",
            "2025-10-24 21:13:40,796 - INFO -   Saved: Sports_and_Outdoors.5core.train.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,798 - INFO - \n",
            "cat=Sports_and_Outdoors - split=train - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,799 - INFO - Input: Sports_and_Outdoors.5core.train.parquet \n",
            " → Output: Sports_and_Outdoors.5core.train.big.parquet\n",
            "2025-10-24 21:13:40,799 - INFO - Skip: Sports_and_Outdoors.5core.train.big.parquet\n",
            "2025-10-24 21:13:40,799 - INFO - \n",
            "cat=Sports_and_Outdoors - split=valid - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,799 - INFO - Input: Sports_and_Outdoors.5core.valid.parquet \n",
            " → Output: Sports_and_Outdoors.5core.valid.large.parquet\n",
            "2025-10-24 21:13:40,800 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:40,800 - INFO -   Input:  Sports_and_Outdoors.5core.valid.parquet\n",
            "2025-10-24 21:13:40,800 - INFO -   Output: Sports_and_Outdoors.5core.valid.large.parquet\n",
            "2025-10-24 21:13:40,842 - INFO -   Total users: 409,772\n",
            "2025-10-24 21:13:40,847 - INFO -   Filtered: 14 ratings, 14 users\n",
            "2025-10-24 21:13:40,849 - INFO -   Saved: Sports_and_Outdoors.5core.valid.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,849 - INFO - \n",
            "cat=Sports_and_Outdoors - split=valid - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,849 - INFO - Input: Sports_and_Outdoors.5core.valid.parquet \n",
            " → Output: Sports_and_Outdoors.5core.valid.big.parquet\n",
            "2025-10-24 21:13:40,850 - INFO - Skip: Sports_and_Outdoors.5core.valid.big.parquet\n",
            "2025-10-24 21:13:40,850 - INFO - \n",
            "cat=Sports_and_Outdoors - split=test - sample=large - n=50000 sampling...\n",
            "2025-10-24 21:13:40,850 - INFO - Input: Sports_and_Outdoors.5core.test.parquet \n",
            " → Output: Sports_and_Outdoors.5core.test.large.parquet\n",
            "2025-10-24 21:13:40,851 - INFO - \n",
            "Sampling 50000 users\n",
            "2025-10-24 21:13:40,851 - INFO -   Input:  Sports_and_Outdoors.5core.test.parquet\n",
            "2025-10-24 21:13:40,851 - INFO -   Output: Sports_and_Outdoors.5core.test.large.parquet\n",
            "2025-10-24 21:13:40,892 - INFO -   Total users: 409,772\n",
            "2025-10-24 21:13:40,899 - INFO -   Filtered: 12 ratings, 12 users\n",
            "2025-10-24 21:13:40,901 - INFO -   Saved: Sports_and_Outdoors.5core.test.large.parquet\n",
            "\n",
            "2025-10-24 21:13:40,901 - INFO - \n",
            "cat=Sports_and_Outdoors - split=test - sample=big - n=50000 sampling...\n",
            "2025-10-24 21:13:40,902 - INFO - Input: Sports_and_Outdoors.5core.test.parquet \n",
            " → Output: Sports_and_Outdoors.5core.test.big.parquet\n",
            "2025-10-24 21:13:40,902 - INFO - Skip: Sports_and_Outdoors.5core.test.big.parquet\n",
            "2025-10-24 21:13:40,902 - INFO - \n",
            " COMPLETED\n"
          ]
        }
      ],
      "source": [
        "run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diagnose_dataset(category: str, suffix: str = 'small'):\n",
        "    safe_cat = category.replace('/', '-')\n",
        "    logger.log_info(\"=\"*70)\n",
        "    logger.log_info(f\"DIAGNOSTIC: {category} (suffix={suffix})\")\n",
        "    logger.log_info(\"=\"*70)\n",
        "    \n",
        "    train = PROCESSED_DIR / f\"{safe_cat}.5core.train.{suffix}.parquet\"\n",
        "    valid = PROCESSED_DIR / f\"{safe_cat}.5core.valid.{suffix}.parquet\"\n",
        "    test = PROCESSED_DIR / f\"{safe_cat}.5core.test.{suffix}.parquet\"\n",
        "    \n",
        "    if not train.exists():\n",
        "        logger.log_error(f\"File not found: {train.name}\")\n",
        "        return\n",
        "    \n",
        "    df_train = pl.read_parquet(train)\n",
        "    df_valid = pl.read_parquet(valid) if valid.exists() else None\n",
        "    df_test = pl.read_parquet(test) if test.exists() else None\n",
        "    \n",
        "    def stats(df, name):\n",
        "        u, i, r = df['user_id'].n_unique(), df['parent_asin'].n_unique(), len(df)\n",
        "        s = 1 - (r / (u * i))\n",
        "        logger.log_info(f\"{name}: {r:,} ratings, {u:,} users, {i:,} items, sparsity {s:.2%}\")\n",
        "        return u, i, r\n",
        "    \n",
        "    train_u, train_i, train_r = stats(df_train, \"TRAIN\")\n",
        "    \n",
        "    if df_valid is not None:\n",
        "        valid_u, valid_i, valid_r = stats(df_valid, \"VALID\")\n",
        "        train_users = set(df_train['user_id'].unique())\n",
        "        valid_users = set(df_valid['user_id'].unique())\n",
        "        train_items = set(df_train['parent_asin'].unique())\n",
        "        valid_items = set(df_valid['parent_asin'].unique())\n",
        "        user_overlap = len(train_users & valid_users)\n",
        "        item_overlap = len(train_items & valid_items)\n",
        "        logger.log_info(f\"\\nOVERLAP:\")\n",
        "        logger.log_info(f\"  Users: {user_overlap:,} / {valid_u:,} ({user_overlap/valid_u*100:.1f}%)\")\n",
        "        logger.log_info(f\"  Items: {item_overlap:,} / {valid_i:,} ({item_overlap/valid_i*100:.1f}%)\")\n",
        "        if user_overlap < valid_u:\n",
        "            logger.log_warning(f\"  {valid_u - user_overlap:,} valid users NOT in train!\")\n",
        "        if item_overlap < valid_i:\n",
        "            logger.log_warning(f\"  {valid_i - item_overlap:,} valid items NOT in train!\")\n",
        "    \n",
        "    if df_test is not None:\n",
        "        stats(df_test, \"TEST\")\n",
        "    \n",
        "    logger.log_info(\"=\"*70 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-24 21:13:40,926 - INFO - ======================================================================\n",
            "2025-10-24 21:13:40,961 - INFO - DIAGNOSTIC: Electronics (suffix=big)\n",
            "2025-10-24 21:13:40,962 - INFO - ======================================================================\n",
            "2025-10-24 21:13:40,983 - INFO - TRAIN: 85,890 ratings, 35,494 users, 82 items, sparsity 97.05%\n",
            "2025-10-24 21:13:40,983 - INFO - VALID: 858 ratings, 858 users, 81 items, sparsity 98.77%\n",
            "2025-10-24 21:13:40,990 - INFO - \n",
            "OVERLAP:\n",
            "2025-10-24 21:13:40,990 - INFO -   Users: 858 / 858 (100.0%)\n",
            "2025-10-24 21:13:40,991 - INFO -   Items: 81 / 81 (100.0%)\n",
            "2025-10-24 21:13:40,991 - INFO - TEST: 675 ratings, 675 users, 76 items, sparsity 98.68%\n",
            "2025-10-24 21:13:40,991 - INFO - ======================================================================\n",
            "\n",
            "2025-10-24 21:13:40,993 - INFO - ======================================================================\n",
            "2025-10-24 21:13:40,993 - INFO - DIAGNOSTIC: Beauty_and_Personal_Care (suffix=big)\n",
            "2025-10-24 21:13:40,993 - INFO - ======================================================================\n",
            "2025-10-24 21:13:40,997 - INFO - TRAIN: 7,718 ratings, 6,613 users, 8 items, sparsity 85.41%\n",
            "2025-10-24 21:13:40,998 - INFO - VALID: 66 ratings, 66 users, 8 items, sparsity 87.50%\n",
            "2025-10-24 21:13:40,999 - INFO - \n",
            "OVERLAP:\n",
            "2025-10-24 21:13:40,999 - INFO -   Users: 66 / 66 (100.0%)\n",
            "2025-10-24 21:13:40,999 - INFO -   Items: 8 / 8 (100.0%)\n",
            "2025-10-24 21:13:41,000 - INFO - TEST: 65 ratings, 65 users, 8 items, sparsity 87.50%\n",
            "2025-10-24 21:13:41,000 - INFO - ======================================================================\n",
            "\n",
            "2025-10-24 21:13:41,000 - INFO - ======================================================================\n",
            "2025-10-24 21:13:41,001 - INFO - DIAGNOSTIC: Sports_and_Outdoors (suffix=big)\n",
            "2025-10-24 21:13:41,001 - INFO - ======================================================================\n",
            "2025-10-24 21:13:41,004 - INFO - TRAIN: 3,250 ratings, 3,079 users, 3 items, sparsity 64.82%\n",
            "2025-10-24 21:13:41,004 - INFO - VALID: 15 ratings, 15 users, 3 items, sparsity 66.67%\n",
            "2025-10-24 21:13:41,005 - INFO - \n",
            "OVERLAP:\n",
            "2025-10-24 21:13:41,005 - INFO -   Users: 15 / 15 (100.0%)\n",
            "2025-10-24 21:13:41,005 - INFO -   Items: 3 / 3 (100.0%)\n",
            "2025-10-24 21:13:41,006 - INFO - TEST: 11 ratings, 11 users, 3 items, sparsity 66.67%\n",
            "2025-10-24 21:13:41,006 - INFO - ======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for cat in Configurations.CATEGORIES:\n",
        "    diagnose_dataset(cat, \"small\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
